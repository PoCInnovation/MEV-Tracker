{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # np est un raccourci pour numpy. Cela vous permettra de taper uniquement np.exp() au lieu de numpy.exp()\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    x -- un nombre scalaire ou un numpy array de n'importe quelle taille\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Début du code ### (≈ 1 ligne de code)\n",
    "    s = 1 / (1 + np.exp(x * -1))\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81757448, 0.92414182, 0.97068777])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1.5, 2.5, 3.5])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_deriv(x):\n",
    "    \"\"\"    \n",
    "    Arguments:\n",
    "    x -- un nombre scalaire ou un numpy array\n",
    "\n",
    "    Return:\n",
    "    ds -- votre gradient\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Début du code ### (≈ 2 lignes de code)\n",
    "    s = sigmoid(x)\n",
    "    ds = s * (1 - s)\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_deriv(x) = [0.14914645 0.07010372 0.02845302]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1.5, 2.5, 3.5])\n",
    "print (\"sigmoid_deriv(x) = \" + str(sigmoid_deriv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_vector(image):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    image -- un numpy array de shape (longueur, largeur, profondeur)\n",
    "    \n",
    "    Returns:\n",
    "    v -- un vecteur de shape (longueur*largeur*profondeur, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Début du code ### (≈ 1 ligne de code)\n",
    "    v = np.reshape(image, image.size)\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_to_vector(image) = [0.67126139 0.29381281 0.90714982 0.52835547 0.42245251 0.45012151\n",
      " 0.92814219 0.96677647 0.85114703 0.52351845 0.19981397 0.27417313\n",
      " 0.6213595  0.00531265 0.1210313  0.49974237 0.3432129  0.94631277]\n"
     ]
    }
   ],
   "source": [
    "# Il s'agit d'un array de shape (3, 3, 2). En général, les images seront de shape (nb_pix_x, nb_pix_y, 3) où 3 représenteront les valeurs RGB\n",
    "image = np.array([[[ 0.67126139,  0.29381281],\n",
    "        [ 0.90714982,  0.52835547],\n",
    "        [ 0.42245251 ,  0.45012151]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85114703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.6213595,  0.00531265],\n",
    "        [ 0.1210313,  0.49974237],\n",
    "        [ 0.3432129,  0.94631277]]])\n",
    "print (\"image_to_vector(image) = \" + str(image_to_vector(image)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rows(x):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    x -- une matrice numpy x de shape (n, m)\n",
    "    \n",
    "    Returns:\n",
    "    x -- la matrice normalisée x\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Début du code ### (≈ 2 lignes de code)\n",
    "    # Calculez d'abord la norme de x. Utilisez np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "    x_norm = np.linalg.norm(x, ord = 2, axis = 1, keepdims = True)\n",
    "    \n",
    "    # Divisez x par x_norm.\n",
    "    x = x / x_norm\n",
    "    ### Fin du code ###\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize_rows(x) = [[0.28571429 0.42857143 0.85714286]\n",
      " [0.51847585 0.20739034 0.82956136]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [2, 3, 6],\n",
    "    [5, 2, 8]])\n",
    "print(\"normalize_rows(x) = \" + str(normalize_rows(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    x -- Un vecteur ou une matrice numpy de shape (n,m)\n",
    "\n",
    "    Returns:\n",
    "    s -- Une matrice numpy égale au softmax de x, de shape (n,m)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Début du code ### (≈ 3 lignes de code)\n",
    "    # Calculez l'exponentielle de chaque élément de x. Utilisez np.exp()\n",
    "    x_exp = np.exp(x)\n",
    "\n",
    "    # Créez un vecteur x_sum qui fait la somme de chaque ligne de x_exp. Utilisez np.sum(..., axis = 1, keepdims = True)\n",
    "    x_sum = np.sum(x_exp, axis = 1, keepdims = True)\n",
    "    \n",
    "    # Calculer softmax(x) en divisant x_exp par x_sum. Cela utilisera automatiquement le broadcasting de numpy.\n",
    "    s = x_exp / x_sum\n",
    "    ### Fin du code ###\n",
    "    print(x_exp.shape, x_sum.shape, s.shape)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5) (1, 1) (1, 5)\n",
      "softmax(x_vect) = [[9.92941993e-01 6.69039052e-03 1.22538777e-04 1.22538777e-04\n",
      "  1.22538777e-04]]\n",
      "(2, 5) (2, 1) (2, 5)\n",
      "softmax(x_matr) = [[1.64525645e-03 6.63743823e-01 8.98279582e-02 6.05256022e-04\n",
      "  2.44177707e-01]\n",
      " [2.38906644e-01 6.49415590e-01 1.18944614e-02 8.78888428e-02\n",
      "  1.18944614e-02]]\n"
     ]
    }
   ],
   "source": [
    "x_vect = np.array([[9, 4, 0, 0 ,0]]) #sisi 94 RPZ\n",
    "\n",
    "print(\"softmax(x_vect) = \" + str(softmax(x_vect)))\n",
    "\n",
    "x_matr = np.array([\n",
    "    [1, 7, 5, 0, 6],\n",
    "    [3, 4, 0, 2 ,0]])\n",
    "\n",
    "print(\"softmax(x_matr) = \" + str(softmax(x_matr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### Implémentation classique d'un produit dot de vecteurs ###\n",
    "tic = time.process_time()\n",
    "dot = 0\n",
    "for i in range(len(x1)):\n",
    "    dot += x1[i] * x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Temps de calcul = \" + str(1000*(toc - tic)) + \"ms\\n\")\n",
    "\n",
    "### Implémentation classique d'un produit outer ###\n",
    "tic = time.process_time()\n",
    "outer = np.zeros((len(x1),len(x2))) # on crée une matrice de taille len(x1)*len(x2) matrix avec que des 0\n",
    "for i in range(len(x1)):\n",
    "    for j in range(len(x2)):\n",
    "        outer[i,j] = x1[i] * x2[j]\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Temps de calcul = \" + str(1000*(toc - tic)) + \"ms\\n\")\n",
    "\n",
    "### Implémentation classique élément-wise ###\n",
    "tic = time.process_time()\n",
    "mul = np.zeros(len(x1))\n",
    "for i in range(len(x1)):\n",
    "    mul[i] = x1[i] * x2[i]\n",
    "toc = time.process_time()\n",
    "print (\"multiplication élément-wise = \" + str(mul) + \"\\n ----- Temps de calcul = \" + str(1000*(toc - tic)) + \"ms\\n\")\n",
    "\n",
    "### Implémentation classique général d'un produit dot ###\n",
    "W = np.random.rand(3, len(x1)) # Random 3*len(x1) numpy array\n",
    "tic = time.process_time()\n",
    "gdot = np.zeros(W.shape[0])\n",
    "for i in range(W.shape[0]):\n",
    "    for j in range(len(x1)):\n",
    "        gdot[i] += W[i,j]*x1[j]\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(gdot) + \"\\n ----- Temps de calcul = \" + str(1000*(toc - tic)) + \"ms\")\n",
    "\n",
    "x1 = [9, 2, 5, 0, 0, 7, 5, 0, 0, 0, 9, 2, 5, 0, 0]\n",
    "x2 = [9, 2, 2, 9, 0, 9, 2, 5, 0, 0, 9, 2, 5, 0, 0]\n",
    "\n",
    "### Implémentation numpy du produit dot ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"dot = \" + str(dot) + \"\\n ----- Temps de calcul = \" + str(1000*(toc - tic)) + \"ms\\n\")\n",
    "\n",
    "### Implémentation numpy de l'outer ###\n",
    "tic = time.process_time()\n",
    "outer = np.outer(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"outer = \" + str(outer) + \"\\n ----- Temps de calcul = \" + str(1000*(toc - tic)) + \"ms\\n\")\n",
    "\n",
    "### Implémentation numpy de l'élement-wise ###\n",
    "tic = time.process_time()\n",
    "mul = np.multiply(x1,x2)\n",
    "toc = time.process_time()\n",
    "print (\"elementwise multiplication = \" + str(mul) + \"\\n ----- Temps de calcul = \" + str(1000*(toc - tic)) + \"ms\\n\")\n",
    "\n",
    "### Implémentation numpy du dot général ###\n",
    "tic = time.process_time()\n",
    "dot = np.dot(W,x1)\n",
    "toc = time.process_time()\n",
    "print (\"gdot = \" + str(dot) + \"\\n ----- Temps de calcul = \" + str(1000*(toc - tic)) + \"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L1_function(y_predicted, y):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    y_predicted -- vecteur de size m contenant vos valeurs prédites\n",
    "    y -- vecteur de size m contenant les vraies valeurs\n",
    "    \n",
    "    Returns:\n",
    "    L1 -- valeur de la fonction de loss L1\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Début du code ### (≈ 1 ligne de code)\n",
    "    L1 = None\n",
    "    ### Fin du code ###\n",
    "    \n",
    "    return L1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
